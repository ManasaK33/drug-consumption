{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\", delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 32 columns):\n",
      "ID           1319 non-null int64\n",
      "Age          1319 non-null float64\n",
      "Gender       1319 non-null float64\n",
      "Education    1319 non-null float64\n",
      "Country      1319 non-null float64\n",
      "Ethnicity    1319 non-null float64\n",
      "Nscore       1319 non-null float64\n",
      "Escore       1319 non-null float64\n",
      "Oscore       1319 non-null float64\n",
      "Ascore       1319 non-null float64\n",
      "Cscore       1319 non-null float64\n",
      "Impulsive    1319 non-null float64\n",
      "SS           1319 non-null float64\n",
      "Alcohol      1319 non-null object\n",
      "Amphet       1319 non-null object\n",
      "Amyl         1319 non-null object\n",
      "Benzos       1319 non-null object\n",
      "Caff         1319 non-null object\n",
      "Cannabis     1319 non-null object\n",
      "Choc         1319 non-null object\n",
      "Coke         1319 non-null object\n",
      "Crack        1319 non-null object\n",
      "Ecstacy      1319 non-null object\n",
      "Heroin       1319 non-null object\n",
      "Ketamine     1319 non-null object\n",
      "Legalh       1319 non-null object\n",
      "LSD          1319 non-null object\n",
      "Meth         1319 non-null object\n",
      "Mushrooms    1319 non-null object\n",
      "Nicotine     1319 non-null object\n",
      "Semer        1319 non-null object\n",
      "VSA          1319 non-null object\n",
      "dtypes: float64(12), int64(1), object(19)\n",
      "memory usage: 329.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID, Chocolate, the fake drug Semer, and legal substances\n",
    "train_data.drop(['ID', 'Choc', 'Semer', 'Alcohol', 'Nicotine', 'Caff','Legalh'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.loc[:,'Amphet':]:\n",
    "    # get label encoding for column\n",
    "    train_data[column] = train_data[column].astype('category').cat.codes\n",
    "    train_data[column] = train_data[column].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_drug_user(row):\n",
    "    row = row['Amphet':]\n",
    "    num_zeros = (row == 0).astype(bool).sum()\n",
    "    if num_zeros == row.size:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Drug User'] = train_data.apply(is_drug_user, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 26 columns):\n",
      "Age          1319 non-null float64\n",
      "Gender       1319 non-null float64\n",
      "Education    1319 non-null float64\n",
      "Country      1319 non-null float64\n",
      "Ethnicity    1319 non-null float64\n",
      "Nscore       1319 non-null float64\n",
      "Escore       1319 non-null float64\n",
      "Oscore       1319 non-null float64\n",
      "Ascore       1319 non-null float64\n",
      "Cscore       1319 non-null float64\n",
      "Impulsive    1319 non-null float64\n",
      "SS           1319 non-null float64\n",
      "Amphet       1319 non-null float64\n",
      "Amyl         1319 non-null float64\n",
      "Benzos       1319 non-null float64\n",
      "Cannabis     1319 non-null float64\n",
      "Coke         1319 non-null float64\n",
      "Crack        1319 non-null float64\n",
      "Ecstacy      1319 non-null float64\n",
      "Heroin       1319 non-null float64\n",
      "Ketamine     1319 non-null float64\n",
      "LSD          1319 non-null float64\n",
      "Meth         1319 non-null float64\n",
      "Mushrooms    1319 non-null float64\n",
      "VSA          1319 non-null float64\n",
      "Drug User    1319 non-null bool\n",
      "dtypes: bool(1), float64(25)\n",
      "memory usage: 259.0 KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for random forest\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 100, num = 20)] + [None]\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 20)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "grid = {'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'n_estimators': n_estimators,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest_grid_search = RandomizedSearchCV(estimator = forest, param_distributions = grid, \n",
    "                               n_iter = 100, cv = 10, verbose=2, random_state=0, n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.loc[:, 'Age':'SS']\n",
    "y_train = train_data['Drug User']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_s...\n",
       "                                        'max_depth': [5, 10, 15, 20, 25, 30, 35,\n",
       "                                                      40, 45, 50, 55, 60, 65,\n",
       "                                                      70, 75, 80, 85, 90, 95,\n",
       "                                                      100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 147, 194, 242,\n",
       "                                                         289, 336, 384, 431,\n",
       "                                                         478, 526, 573, 621,\n",
       "                                                         668, 715, 763, 810,\n",
       "                                                         857, 905, 952, 1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 621,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 30,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=621, min_samples_split=2, \n",
    "                                min_samples_leaf=2, max_features='auto', \n",
    "                                max_depth=30, bootstrap=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(forest, X_train, y_train, scoring='f1', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9187101168756463\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
